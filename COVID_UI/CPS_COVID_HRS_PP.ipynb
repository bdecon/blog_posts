{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment and COVID\n",
    "\n",
    "Brian Dew, July 25, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import struct\n",
    "import gzip\n",
    "import shutil\n",
    "from io import BytesIO\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download monthly CPS files if not available in current directory\n",
    "file_list = ['apr19pub.dat', 'may19pub.dat', 'jun19pub.dat', \n",
    "             'apr20pub.dat', 'may20pub.dat', 'jun20pub.dat']\n",
    "for file in file_list:\n",
    "    if file not in os.listdir():\n",
    "        file_loc = f'https://www2.census.gov/programs-surveys/cps/datasets/20{file[3:5]}/basic/{file}.gz'\n",
    "        print(f'Downloading: {file} from census.gov')\n",
    "        r = requests.get(file_loc)\n",
    "        with gzip.open(BytesIO(r.content), 'r') as f_in, open(file, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "            \n",
    "# Download two data dictionaries if not available in current directory\n",
    "dd_list = {'2020_Basic_CPS_Public_Use_Record_Layout_plus_IO_Code_list.txt': 2020, \n",
    "             'January_2017_Record_Layout.txt': 2017}\n",
    "for file, year in dd_list.items():\n",
    "    if file not in os.listdir():\n",
    "        file_loc = f'https://www2.census.gov/programs-surveys/cps/datasets/{year}/basic/{file}'\n",
    "        print(f'Downloading: {file} from census.gov')\n",
    "        r = requests.get(file_loc)\n",
    "        with open(file, 'wb') as f:\n",
    "            f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "\n",
    "Search the data dictionary for `var_names` and pull those columns from microdata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually list out the IDs for series of interest \n",
    "var_names = ['HRMONTH', 'HRYEAR4', 'PRTAGE', 'PRFAMNUM', 'PRDISFLG', 'QSTNUM', \n",
    "             'PEMLR', 'PEHRACTT', 'PEIO1COW', 'PEDWRSN', 'PRWNTJOB', 'PENLFACT',\n",
    "             'PEDWWNTO', 'PRWKSTAT', 'PESCHENR', 'PWSSWGT', 'PWFMWGT', 'HWHHWGT']\n",
    "\n",
    "dd_list = {19: 'January_2017_Record_Layout.txt',\n",
    "           20: '2020_Basic_CPS_Public_Use_Record_Layout_plus_IO_Code_list.txt'}\n",
    "\n",
    "unpackers = {}\n",
    "\n",
    "for year, dd in dd_list.items():\n",
    "    # read data dictionary text file \n",
    "    data_dict = open(dd, 'r', encoding='iso-8859-1').read()\n",
    "\n",
    "    # regular expression matching series name and data dict pattern\n",
    "    p = f'\\n({\"|\".join(var_names)})\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)'\n",
    "\n",
    "    # dictionary of variable name: [start, end, and length + 's']\n",
    "    d = {s[0]: [int(s[2])-1, int(s[3]), f'{s[1]}s']\n",
    "         for s in re.findall(p, data_dict)}\n",
    "\n",
    "    # lists of variable starts, ends, and lengths\n",
    "    start, end, width = zip(*d.values())\n",
    "\n",
    "    # create list of which characters to skip in each row\n",
    "    skip = ([f'{s - e}x' for s, e in zip(start, [0] + list(end[:-1]))])\n",
    "\n",
    "    # create format string by joining skip and variable segments\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, width) for j in i])\n",
    "\n",
    "    # struct can interpret row bytes with the format string\n",
    "    unpackers[year] = struct.Struct(unpack_fmt).unpack_from    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the six monthly files as a pandas dataframe, keep only rows with a person weight greater than zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for file in file_list:\n",
    "    # open file (read as binary) and read lines into \"raw_data\"\n",
    "    raw_data = open(file, 'rb').readlines()\n",
    "\n",
    "    wgt = d['PWSSWGT']  # Location of sample weight variable\n",
    "\n",
    "    # unpack and store data of interest if sample weight > 0\n",
    "    data = [[*map(int, unpackers[int(file[3:5])](row))] for row in raw_data\n",
    "            if int(row[wgt[0]:wgt[1]]) > 0]\n",
    "    \n",
    "    df = df.append(pd.DataFrame(data, columns=d.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniquely identify households and families using these variables\n",
    "hh_grp = ['HRYEAR4', 'HRMONTH', 'QSTNUM']\n",
    "fam_grp = ['HRYEAR4', 'HRMONTH', 'QSTNUM', 'PRFAMNUM']\n",
    "\n",
    "groups = ['U18', 'DIS', 'STU', 'CARE', 'UNEM', 'UNDE', 'ELD', 'SE']\n",
    "\n",
    "# Reason for not being in labor force\n",
    "nilfreason = lambda x: pd.Categorical(\n",
    "    np.where((x['PRWNTJOB']==2) & \n",
    "             ((x['PEMLR']==6) | (x['PENLFACT'].isin([1, 2]))), \n",
    "             'Disabled/Ill',\n",
    "    np.where((x['PRWNTJOB']==2) & (x['PENLFACT']==4), 'Family',\n",
    "    np.where((x['PRWNTJOB']==2) & ((x['PEMLR']==5) | (x['PENLFACT']==5)), \n",
    "             'Retired',\n",
    "    np.where((x['PRWNTJOB']==2) & (x['PENLFACT']==3), 'School',\n",
    "    np.where(x['PEDWWNTO']==1, 'Discouraged',\n",
    "    np.where(x['PEMLR'].isin([5, 6, 7]), 'Other', np.nan)))))))\n",
    "# Part time for economic reasons\n",
    "ptecon = lambda x: pd.Categorical(\n",
    "    np.where(x['PRWKSTAT'].isin([3, 6]), 1, \n",
    "    np.where(x['PRWKSTAT'].between(2, 10), 0, np.nan)))\n",
    "# Marginally attached to labor force\n",
    "mrgnatt = lambda x: pd.Categorical(\n",
    "    np.where(x['PEDWRSN'].between(1, 11), 1, 0))\n",
    "lfs = lambda x: pd.Categorical(\n",
    "    np.where(x['PEMLR'].isin([1, 2]), 'Employed',\n",
    "    np.where(x['PEMLR'].isin([3, 4]), 'Unemployed',\n",
    "    np.where(x['PEMLR'].isin([5, 6, 7]), 'NILF', np.nan))))\n",
    "# Class of worker on main job\n",
    "cow1 = lambda x: pd.Categorical(\n",
    "    np.where(x['PEIO1COW'] == 1, 'Federal Government',\n",
    "    np.where(x['PEIO1COW'] == 2, 'State Government',\n",
    "    np.where(x['PEIO1COW'] == 3, 'Local Government',\n",
    "    np.where(x['PEIO1COW'].isin([4, 5]), 'Private',\n",
    "    np.where(x['PEIO1COW'] == 6, 'Self-employed Incorporated',\n",
    "    np.where(x['PEIO1COW'] == 7, 'Self-employed Unincorporated',\n",
    "    np.where(x['PEIO1COW'] == 8, 'Without Pay', np.nan))))))))\n",
    "\n",
    "df = df.assign(NILFREASON = nilfreason, PTECON = ptecon, \n",
    "               MRGNATT = mrgnatt, LFS = lfs, COW1 = cow1)\n",
    "\n",
    "df['PWFMWGT'] = df['PWFMWGT'] / 10000.0\n",
    "df['PWSSWGT'] = df['PWSSWGT'] / 10000.0\n",
    "df['HWHHWGT'] = df['HWHHWGT'] / 10000.0\n",
    "\n",
    "df['PEHRACTT'].replace(-1, 0, inplace=True)\n",
    "df['FMHRST'] = df.groupby(fam_grp)['PEHRACTT'].transform('sum')\n",
    "df['FMNUM'] = df.groupby(fam_grp)['PWSSWGT'].transform('count')\n",
    "df['FMHRSPP'] = df['FMHRST'] / df['FMNUM']\n",
    "df['HHHRST'] = df.groupby(hh_grp)['PEHRACTT'].transform('sum')\n",
    "df['HHNUM'] = df.groupby(hh_grp)['PWSSWGT'].transform('count')\n",
    "df['HHHRSPP'] = df['HHHRST'] / df['HHNUM']\n",
    "df['U18'] = np.where(df['PRTAGE'] < 18, 1, 0)\n",
    "df['DIS'] = np.where((df['PRDISFLG'] == 1) | (df['NILFREASON'] == 'Disabled/Ill'), 1, 0)\n",
    "df['STU'] = np.where((df['PESCHENR'] == 1) | (df['NILFREASON'] == 'School'), 1, 0)\n",
    "df['CARE'] = np.where(df['NILFREASON'] == 'Family', 1, 0)\n",
    "df['UNEM'] = np.where(df['LFS'] == 'Unemployed', 1, 0)\n",
    "df['UNDE'] = np.where((df['LFS'] == 'Unemployed') | (df['MRGNATT'] == 1) | \n",
    "                      (df['PTECON'] == 1) | \n",
    "                      (df['NILFREASON'] == 'Discouraged'), 1, 0)\n",
    "df['ELD'] = np.where(df['PRTAGE'] > 64, 1, 0)\n",
    "df['SE'] = np.where((df['COW1'] == 'Self-employed Incorporated') | \n",
    "                    (df['COW1'] == 'Self-employed Unincorporated'), 1, 0)\n",
    "\n",
    "# Family level summary\n",
    "for group in groups:\n",
    "    df['FM' + group] = df.groupby(fam_grp)[group].transform('sum')\n",
    "df['ANY'] = df[['FM' + group for group in groups]].sum(axis=1)\n",
    "\n",
    "# Household level summary\n",
    "for group in groups:\n",
    "    df['HH' + group] = df.groupby(hh_grp)[group].transform('sum')\n",
    "df['ANY'] = df[['HH' + group for group in groups]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first row from each family\n",
    "fam_data = df.groupby(fam_grp).nth(0).reset_index()\n",
    "\n",
    "names = {'U18': 'Children', 'DIS': 'Persons with Disabilities', 'STU': 'Students',\n",
    "         'CARE': 'Unpaid caregivers', 'UNEM': 'Unemployed', 'UNDE': 'Underutilized',\n",
    "         'ELD': 'Elderly', 'SE': 'Self-Employed'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "Total, All Families: \n",
      " Number of Families:  139,422,336\n",
      " Total hours worked per person in reference week:  19.5\n",
      "Family contains one or more:\n",
      "Children : \n",
      " Number of Families:  39,323,672\n",
      " Share of Families:  28.2%\n",
      " Total hours worked per person in reference week:  14.9\n",
      "Persons with Disabilities : \n",
      " Number of Families:  31,026,519\n",
      " Share of Families:  22.3%\n",
      " Total hours worked per person in reference week:  8.7\n",
      "Students : \n",
      " Number of Families:  21,893,624\n",
      " Share of Families:  15.7%\n",
      " Total hours worked per person in reference week:  17.6\n",
      "Unpaid caregivers : \n",
      " Number of Families:  12,519,184\n",
      " Share of Families:  9.0%\n",
      " Total hours worked per person in reference week:  10.5\n",
      "Unemployed : \n",
      " Number of Families:  5,281,584\n",
      " Share of Families:  3.8%\n",
      " Total hours worked per person in reference week:  9.1\n",
      "Underutilized : \n",
      " Number of Families:  13,198,567\n",
      " Share of Families:  9.5%\n",
      " Total hours worked per person in reference week:  12.6\n",
      "Elderly : \n",
      " Number of Families:  39,500,204\n",
      " Share of Families:  28.3%\n",
      " Total hours worked per person in reference week:  8.2\n",
      "Self-Employed : \n",
      " Number of Families:  14,074,686\n",
      " Share of Families:  10.1%\n",
      " Total hours worked per person in reference week:  26.6\n",
      "Family contains any of above groups: \n",
      " Number of Families:  110,414,307\n",
      " Share of Families:  79.2%\n",
      " Total hours worked per person in reference week:  14.9\n",
      "Family contains none of above groups: \n",
      " Number of Families:  29,008,029\n",
      " Share of Families:  20.8%\n",
      " Total hours worked per person in reference week:  37.0\n",
      "\n",
      "2020\n",
      "Total, All Families: \n",
      " Number of Families:  137,579,851\n",
      " Total hours worked per person in reference week:  16.0\n",
      "Family contains one or more:\n",
      "Children : \n",
      " Number of Families:  38,300,074\n",
      " Share of Families:  27.8%\n",
      " Total hours worked per person in reference week:  12.6\n",
      "Persons with Disabilities : \n",
      " Number of Families:  29,496,754\n",
      " Share of Families:  21.4%\n",
      " Total hours worked per person in reference week:  7.1\n",
      "Students : \n",
      " Number of Families:  20,896,248\n",
      " Share of Families:  15.2%\n",
      " Total hours worked per person in reference week:  14.4\n",
      "Unpaid caregivers : \n",
      " Number of Families:  12,410,928\n",
      " Share of Families:  9.0%\n",
      " Total hours worked per person in reference week:  9.1\n",
      "Unemployed : \n",
      " Number of Families:  17,116,017\n",
      " Share of Families:  12.4%\n",
      " Total hours worked per person in reference week:  7.8\n",
      "Underutilized : \n",
      " Number of Families:  30,973,692\n",
      " Share of Families:  22.5%\n",
      " Total hours worked per person in reference week:  10.3\n",
      "Elderly : \n",
      " Number of Families:  40,533,423\n",
      " Share of Families:  29.5%\n",
      " Total hours worked per person in reference week:  6.5\n",
      "Self-Employed : \n",
      " Number of Families:  14,335,891\n",
      " Share of Families:  10.4%\n",
      " Total hours worked per person in reference week:  20.8\n",
      "Family contains any of above groups: \n",
      " Number of Families:  113,532,586\n",
      " Share of Families:  82.5%\n",
      " Total hours worked per person in reference week:  12.1\n",
      "Family contains none of above groups: \n",
      " Number of Families:  24,047,264\n",
      " Share of Families:  17.5%\n",
      " Total hours worked per person in reference week:  34.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for year in [2019, 2020]:\n",
    "    print(year)\n",
    "    data = fam_data.query('HRYEAR4 == @year')\n",
    "    print('Total, All Families: ')\n",
    "    num = data.PWFMWGT.sum() / 3\n",
    "    print(' Number of Families: ', f'{num:,.0f}')\n",
    "    val = np.average(data['FMHRSPP'], weights=data['PWFMWGT'])\n",
    "    print(' Total hours worked per person in reference week: ', f'{val:.1f}')\n",
    "    print('Family contains one or more:')\n",
    "    for group in groups:\n",
    "        fmgroup = 'FM' + group\n",
    "        d = data.loc[data[fmgroup] > 0]\n",
    "        n = d.PWFMWGT.sum () / 3\n",
    "        print(names[group], ': ')\n",
    "        print(' Number of Families: ', f'{n:,.0f}')\n",
    "        print(' Share of Families: ', f'{(n/num)*100:.1f}%')\n",
    "        val = np.average(d['FMHRSPP'], weights=d['PWFMWGT'])\n",
    "        print(' Total hours worked per person in reference week: ', f'{val:.1f}')\n",
    "    print('Family contains any of above groups: ')\n",
    "    d = data.loc[data['ANY'] > 0]\n",
    "    n = d.PWFMWGT.sum () / 3\n",
    "    print(' Number of Families: ', f'{n:,.0f}')\n",
    "    print(' Share of Families: ', f'{(n/num)*100:.1f}%')\n",
    "    val = np.average(d['FMHRSPP'], weights=d['PWFMWGT'])\n",
    "    print(' Total hours worked per person in reference week: ', f'{val:.1f}')\n",
    "    print('Family contains none of above groups: ')\n",
    "    d = data.loc[data['ANY'] == 0]\n",
    "    n = d.PWFMWGT.sum () / 3\n",
    "    print(' Number of Families: ', f'{n:,.0f}')\n",
    "    print(' Share of Families: ', f'{(n/num)*100:.1f}%')\n",
    "    val = np.average(d['FMHRSPP'], weights=d['PWFMWGT'])\n",
    "    print(' Total hours worked per person in reference week: ', f'{val:.1f}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "Total, All Households: \n",
      " Number of Households:  129,569,014\n",
      " Total hours worked per person in reference week:  19.4\n",
      "Household contains one or more:\n",
      "Children : \n",
      " Number of Households:  38,197,586\n",
      " Share of Households:  29.5%\n",
      " Total hours worked per person in reference week:  15.6\n",
      "Persons with Disabilities : \n",
      " Number of Households:  30,631,958\n",
      " Share of Households:  23.6%\n",
      " Total hours worked per person in reference week:  9.0\n",
      "Students : \n",
      " Number of Households:  21,425,706\n",
      " Share of Households:  16.5%\n",
      " Total hours worked per person in reference week:  18.1\n",
      "Unpaid caregivers : \n",
      " Number of Households:  12,372,922\n",
      " Share of Households:  9.5%\n",
      " Total hours worked per person in reference week:  11.5\n",
      "Unemployed : \n",
      " Number of Households:  5,216,888\n",
      " Share of Households:  4.0%\n",
      " Total hours worked per person in reference week:  10.1\n",
      "Underutilized : \n",
      " Number of Households:  12,930,018\n",
      " Share of Households:  10.0%\n",
      " Total hours worked per person in reference week:  13.2\n",
      "Elderly : \n",
      " Number of Households:  39,399,243\n",
      " Share of Households:  30.4%\n",
      " Total hours worked per person in reference week:  8.4\n",
      "Self-Employed : \n",
      " Number of Households:  13,977,287\n",
      " Share of Households:  10.8%\n",
      " Total hours worked per person in reference week:  26.2\n",
      "Family contains any of above groups: \n",
      " Number of Households:  100,910,312\n",
      " Share of Households:  77.9%\n",
      " Total hours worked per person in reference week:  14.4\n",
      "Family contains none of above groups: \n",
      " Number of Households:  28,658,702\n",
      " Share of Households:  22.1%\n",
      " Total hours worked per person in reference week:  37.0\n",
      "\n",
      "2020\n",
      "Total, All Households: \n",
      " Number of Households:  127,935,580\n",
      " Total hours worked per person in reference week:  16.1\n",
      "Household contains one or more:\n",
      "Children : \n",
      " Number of Households:  37,079,493\n",
      " Share of Households:  29.0%\n",
      " Total hours worked per person in reference week:  13.1\n",
      "Persons with Disabilities : \n",
      " Number of Households:  29,055,753\n",
      " Share of Households:  22.7%\n",
      " Total hours worked per person in reference week:  7.4\n",
      "Students : \n",
      " Number of Households:  20,421,575\n",
      " Share of Households:  16.0%\n",
      " Total hours worked per person in reference week:  14.9\n",
      "Unpaid caregivers : \n",
      " Number of Households:  12,233,380\n",
      " Share of Households:  9.6%\n",
      " Total hours worked per person in reference week:  9.8\n",
      "Unemployed : \n",
      " Number of Households:  16,647,093\n",
      " Share of Households:  13.0%\n",
      " Total hours worked per person in reference week:  8.5\n",
      "Underutilized : \n",
      " Number of Households:  29,827,979\n",
      " Share of Households:  23.3%\n",
      " Total hours worked per person in reference week:  10.9\n",
      "Elderly : \n",
      " Number of Households:  40,439,411\n",
      " Share of Households:  31.6%\n",
      " Total hours worked per person in reference week:  6.7\n",
      "Self-Employed : \n",
      " Number of Households:  14,231,986\n",
      " Share of Households:  11.1%\n",
      " Total hours worked per person in reference week:  20.5\n",
      "Family contains any of above groups: \n",
      " Number of Households:  104,154,645\n",
      " Share of Households:  81.4%\n",
      " Total hours worked per person in reference week:  11.8\n",
      "Family contains none of above groups: \n",
      " Number of Households:  23,780,935\n",
      " Share of Households:  18.6%\n",
      " Total hours worked per person in reference week:  34.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take first row from each family\n",
    "hh_data = df.groupby(hh_grp).nth(0).reset_index()\n",
    "\n",
    "for year in [2019, 2020]:\n",
    "    print(year)\n",
    "    data = hh_data.query('HRYEAR4 == @year')\n",
    "    print('Total, All Households: ')\n",
    "    num = data.HWHHWGT.sum() / 3\n",
    "    print(' Number of Households: ', f'{num:,.0f}')\n",
    "    val = np.average(data['HHHRSPP'], weights=data['HWHHWGT'])\n",
    "    print(' Total hours worked per person in reference week: ', f'{val:.1f}')\n",
    "    print('Household contains one or more:')\n",
    "    for group in groups:\n",
    "        hhgroup = 'HH' + group\n",
    "        d = data.loc[data[hhgroup] > 0]\n",
    "        n = d.HWHHWGT.sum () / 3\n",
    "        print(names[group], ': ')\n",
    "        print(' Number of Households: ', f'{n:,.0f}')\n",
    "        print(' Share of Households: ', f'{(n/num)*100:.1f}%')\n",
    "        val = np.average(d['HHHRSPP'], weights=d['HWHHWGT'])\n",
    "        print(' Total hours worked per person in reference week: ', f'{val:.1f}')\n",
    "    print('Family contains any of above groups: ')\n",
    "    d = data.loc[data['ANY'] > 0]\n",
    "    n = d.HWHHWGT.sum () / 3\n",
    "    print(' Number of Households: ', f'{n:,.0f}')\n",
    "    print(' Share of Households: ', f'{(n/num)*100:.1f}%')\n",
    "    val = np.average(d['HHHRSPP'], weights=d['HWHHWGT'])\n",
    "    print(' Total hours worked per person in reference week: ', f'{val:.1f}')\n",
    "    print('Family contains none of above groups: ')\n",
    "    d = data.loc[data['ANY'] == 0]\n",
    "    n = d.HWHHWGT.sum () / 3\n",
    "    print(' Number of Households: ', f'{n:,.0f}')\n",
    "    print(' Share of Households: ', f'{(n/num)*100:.1f}%')\n",
    "    val = np.average(d['HHHRSPP'], weights=d['HWHHWGT'])\n",
    "    print(' Total hours worked per person in reference week: ', f'{val:.1f}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April to June 2020 Averages:\n",
      "Unemployed population:  20,535,697\n",
      "Unemployed plus their families:  49,206,196\n",
      "Unemployed family only:  28,670,498\n",
      "Children living with unemployed:  11,334,735\n",
      "Underutilized population:  39,339,577\n",
      "Underutilized plus their families:  87,764,203\n",
      "Unemployed family only:  48,424,625\n",
      "Children living with underutilized:  39,339,577\n",
      "\n",
      "April to June 2019 Averages:\n",
      "Unemployed population:  5,861,173\n",
      "Unemployed plus their families:  15,562,923\n",
      "Unemployed family only:  9,701,750\n",
      "Children living with unemployed:  3,805,562\n",
      "Underutilized population:  15,274,384\n",
      "Underutilized plus their families:  37,914,958\n",
      "Unemployed family only:  22,640,574\n",
      "Children living with underutilized:  15,274,384\n"
     ]
    }
   ],
   "source": [
    "print('April to June 2020 Averages:')\n",
    "df20 = df.query('HRYEAR4 == 2020')\n",
    "unemp = df20.loc[df20['UNEM'] == 1].PWSSWGT.sum() / 3\n",
    "print('Unemployed population: ', f'{unemp:,.0f}')\n",
    "unempfam = df20.loc[(df20['FMUNEM'] > 0), 'PWSSWGT'].sum() / 3\n",
    "print('Unemployed plus their families: ', f'{unempfam:,.0f}')\n",
    "unempfamonly = unempfam - unemp\n",
    "print('Unemployed family only: ', f'{unempfamonly:,.0f}')\n",
    "unempkids = df20.loc[(df20['FMUNEM'] > 0) & (df20['U18'] == 1), 'PWSSWGT'].sum() / 3\n",
    "print('Children living with unemployed: ', f'{unempkids:,.0f}')\n",
    "unde = df20.loc[df20['UNDE'] == 1].PWSSWGT.sum() / 3\n",
    "print('Underutilized population: ', f'{unde:,.0f}')\n",
    "undefam = df20.loc[(df20['FMUNDE'] > 0), 'PWSSWGT'].sum() / 3\n",
    "print('Underutilized plus their families: ', f'{undefam:,.0f}')\n",
    "undefamonly = undefam - unde\n",
    "print('Unemployed family only: ', f'{undefamonly:,.0f}')\n",
    "undekids = df20.loc[(df20['FMUNDE'] > 0) & (df20['U18'] == 1), 'PWSSWGT'].sum() / 3\n",
    "print('Children living with underutilized: ', f'{unde:,.0f}')\n",
    "print('')\n",
    "print('April to June 2019 Averages:')\n",
    "df19 = df.query('HRYEAR4 == 2019')\n",
    "unemp = df19.loc[df19['UNEM'] == 1].PWSSWGT.sum() / 3\n",
    "print('Unemployed population: ', f'{unemp:,.0f}')\n",
    "unempfam = df19.loc[(df19['FMUNEM'] > 0), 'PWSSWGT'].sum() / 3\n",
    "print('Unemployed plus their families: ', f'{unempfam:,.0f}')\n",
    "unempfamonly = unempfam - unemp\n",
    "print('Unemployed family only: ', f'{unempfamonly:,.0f}')\n",
    "unempkids = df19.loc[(df19['FMUNEM'] > 0) & (df19['U18'] == 1), 'PWSSWGT'].sum() / 3\n",
    "print('Children living with unemployed: ', f'{unempkids:,.0f}')\n",
    "unde = df19.loc[df19['UNDE'] == 1].PWSSWGT.sum() / 3\n",
    "print('Underutilized population: ', f'{unde:,.0f}')\n",
    "undefam = df19.loc[(df19['FMUNDE'] > 0), 'PWSSWGT'].sum() / 3\n",
    "print('Underutilized plus their families: ', f'{undefam:,.0f}')\n",
    "undefamonly = undefam - unde\n",
    "print('Unemployed family only: ', f'{undefamonly:,.0f}')\n",
    "undekids = df19.loc[(df19['FMUNDE'] > 0) & (df19['U18'] == 1), 'PWSSWGT'].sum() / 3\n",
    "print('Children living with underutilized: ', f'{unde:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
